{
    "text": " The demo is actually me speaking today. I'm going to get feedback on my presentation itself. So I'll stop it in the middle of the presentation at some point so that it has enough time to spit out an analysis once I'm done. So back to the presentation now. That's the interface, by the way. It's fairly straightforward. There's nothing more to it. There were two ways to input audio clips. One is to record it live, like I'm doing it right now. And the other one is to upload an audio file. Back to the presentation. So the problem statement that I'm trying to tackle here, the main challenge here is obtaining objective, detailed, and actionable feedback on verbal communication skills. So when we give a presentation in a class or anywhere in a professional environment, the feedback we get from our seniors or professors, or even from our friends, it's very subjective. And they don't want to hurt our feelings. So they're not as honest as they ideally should be. And it's very subjective and biased, too, because what an ideal presentation should look like for them could be very different for different people and what it ideally should be. So those are the barriers. And also, people are extremely, like, they're not aware of how they're speaking in a presentation because there's a lot to think about while presenting. Like when you're speaking, you're actually focused on thinking about what you're going to say and trying to make sense. Like, you need to make the content. The flow needs to be such that the content comes across to the audience in a way that it makes sense to them. So you don't have enough bandwidth left to actually focus on your speaking habits, whether you're pacing it properly, whether you're using too many fillers, or whether you're speaking clearly. So there's not enough bandwidth to that. And then again, the human feedback bit, which is very subjective, generic, and heavily sugar-coated. So that's the problem. And the solution is verbal vector. Again, I'll explain the vector a bit later in the name. It doesn't really make sense right now, but then it will make sense soon. So the concept is a web application for now, as you saw in the demo. It'll analyze audio recordings to provide comprehensive communication feedback, which you will see soon, based on whenever I stop the recording. And once the LLM is done processing all of the inputs. And the core pipeline, it looks like this. The input is either you speak to it, you record something live, or you upload an audio clip. And once you do that, the pipeline gets triggered. First, the speech to text bit, which is done using whisper, that gets triggered. And you get a transcription out of it. So your audio is converted to text, and you also get a transcript from it. Once that is done, we move to the feature extraction part, which calculates quantitative metrics from the audio. So we use a library called librosa for that, which is able to calculate these metrics, such as base, pauses, pitch, and volume variation. And then also certain text metrics, such as fill-o-words, how many fill-o-words we use, what were they, sentence length, and unique words. And then scores will be derived from the LLM analysis. This is done once I have the transcript, and the feature is JSON file. I'll combine these two features, the text and the audio features, and make a JSON out of it. These two files will act as context with the LLM with a very well-crafted problem for the LLM, which is, again, a lower fine-tuned llama 3 with 8 billion parameters. And then once the LLM gets all of this as input as context, it will output the feedback in the structured way. And this is where the vector name comes from. Vector storage, I still haven't implemented this in the front end, but then the back end is ready for this. I will implement it soon, maybe after the presentation. Didn't have enough time to do that. So once the transcript is generated by Whisper, the speech-to-text model, the transcript is broken down into multiple chunks, and then it's stored in the vector database in its equivalent vector embedding. And then the ideal use case for this is once you're done with the presentation, once it's gone, there's no way to retrieve whatever is set, or whatever knowledge was delivered. So once you have a transcript for that, you can actually query it, which makes a lot of sense. It's basically like a note-taker. Once you're in class, if you can record it, and then query it later, you have all the notes there. I haven't implemented that yet in the front end, though. I think I should stop the recording now. So that it has...",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 2.8000000000000003,
            "text": " The demo is actually me speaking today.",
            "tokens": [
                50363,
                383,
                13605,
                318,
                1682,
                502,
                5486,
                1909,
                13,
                50503
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 1,
            "seek": 0,
            "start": 2.8000000000000003,
            "end": 5.76,
            "text": " I'm going to get feedback on my presentation itself.",
            "tokens": [
                50503,
                314,
                1101,
                1016,
                284,
                651,
                7538,
                319,
                616,
                10470,
                2346,
                13,
                50651
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 2,
            "seek": 0,
            "start": 5.76,
            "end": 8.68,
            "text": " So I'll stop it in the middle of the presentation",
            "tokens": [
                50651,
                1406,
                314,
                1183,
                2245,
                340,
                287,
                262,
                3504,
                286,
                262,
                10470,
                50797
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 3,
            "seek": 0,
            "start": 8.68,
            "end": 10.24,
            "text": " at some point so that it has enough time",
            "tokens": [
                50797,
                379,
                617,
                966,
                523,
                326,
                340,
                468,
                1576,
                640,
                50875
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 4,
            "seek": 0,
            "start": 10.24,
            "end": 13.8,
            "text": " to spit out an analysis once I'm done.",
            "tokens": [
                50875,
                284,
                27591,
                503,
                281,
                3781,
                1752,
                314,
                1101,
                1760,
                13,
                51053
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 5,
            "seek": 0,
            "start": 13.8,
            "end": 15.56,
            "text": " So back to the presentation now.",
            "tokens": [
                51053,
                1406,
                736,
                284,
                262,
                10470,
                783,
                13,
                51141
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 6,
            "seek": 0,
            "start": 15.56,
            "end": 17.400000000000002,
            "text": " That's the interface, by the way.",
            "tokens": [
                51141,
                1320,
                338,
                262,
                7071,
                11,
                416,
                262,
                835,
                13,
                51233
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 7,
            "seek": 0,
            "start": 17.400000000000002,
            "end": 18.68,
            "text": " It's fairly straightforward.",
            "tokens": [
                51233,
                632,
                338,
                6547,
                15836,
                13,
                51297
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 8,
            "seek": 0,
            "start": 18.68,
            "end": 19.92,
            "text": " There's nothing more to it.",
            "tokens": [
                51297,
                1318,
                338,
                2147,
                517,
                284,
                340,
                13,
                51359
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 9,
            "seek": 0,
            "start": 19.92,
            "end": 23.04,
            "text": " There were two ways to input audio clips.",
            "tokens": [
                51359,
                1318,
                547,
                734,
                2842,
                284,
                5128,
                6597,
                19166,
                13,
                51515
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 10,
            "seek": 0,
            "start": 23.04,
            "end": 25.560000000000002,
            "text": " One is to record it live, like I'm doing it right now.",
            "tokens": [
                51515,
                1881,
                318,
                284,
                1700,
                340,
                2107,
                11,
                588,
                314,
                1101,
                1804,
                340,
                826,
                783,
                13,
                51641
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 11,
            "seek": 0,
            "start": 25.560000000000002,
            "end": 28.84,
            "text": " And the other one is to upload an audio file.",
            "tokens": [
                51641,
                843,
                262,
                584,
                530,
                318,
                284,
                9516,
                281,
                6597,
                2393,
                13,
                51805
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16920389645341513,
            "compression_ratio": 1.7402135231316727,
            "no_speech_prob": 0.10926856845617294
        },
        {
            "id": 12,
            "seek": 2884,
            "start": 28.919999999999998,
            "end": 31.48,
            "text": " Back to the presentation.",
            "tokens": [
                50367,
                5157,
                284,
                262,
                10470,
                13,
                50495
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 13,
            "seek": 2884,
            "start": 31.48,
            "end": 34.8,
            "text": " So the problem statement that I'm trying to tackle here,",
            "tokens": [
                50495,
                1406,
                262,
                1917,
                2643,
                326,
                314,
                1101,
                2111,
                284,
                9761,
                994,
                11,
                50661
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 14,
            "seek": 2884,
            "start": 34.8,
            "end": 38.44,
            "text": " the main challenge here is obtaining objective,",
            "tokens": [
                50661,
                262,
                1388,
                4427,
                994,
                318,
                16727,
                9432,
                11,
                50843
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 15,
            "seek": 2884,
            "start": 38.44,
            "end": 41.16,
            "text": " detailed, and actionable feedback",
            "tokens": [
                50843,
                6496,
                11,
                290,
                2223,
                540,
                7538,
                50979
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 16,
            "seek": 2884,
            "start": 41.16,
            "end": 44.32,
            "text": " on verbal communication skills.",
            "tokens": [
                50979,
                319,
                17755,
                6946,
                4678,
                13,
                51137
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 17,
            "seek": 2884,
            "start": 44.32,
            "end": 46.36,
            "text": " So when we give a presentation in a class",
            "tokens": [
                51137,
                1406,
                618,
                356,
                1577,
                257,
                10470,
                287,
                257,
                1398,
                51239
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 18,
            "seek": 2884,
            "start": 46.36,
            "end": 49.2,
            "text": " or anywhere in a professional environment,",
            "tokens": [
                51239,
                393,
                6609,
                287,
                257,
                4708,
                2858,
                11,
                51381
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 19,
            "seek": 2884,
            "start": 49.2,
            "end": 51.84,
            "text": " the feedback we get from our seniors or professors,",
            "tokens": [
                51381,
                262,
                7538,
                356,
                651,
                422,
                674,
                23481,
                393,
                20339,
                11,
                51513
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 20,
            "seek": 2884,
            "start": 51.84,
            "end": 54.24,
            "text": " or even from our friends, it's very subjective.",
            "tokens": [
                51513,
                393,
                772,
                422,
                674,
                2460,
                11,
                340,
                338,
                845,
                19088,
                13,
                51633
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 21,
            "seek": 2884,
            "start": 54.24,
            "end": 56.36,
            "text": " And they don't want to hurt our feelings.",
            "tokens": [
                51633,
                843,
                484,
                836,
                470,
                765,
                284,
                5938,
                674,
                7666,
                13,
                51739
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1572639646984282,
            "compression_ratio": 1.7125506072874495,
            "no_speech_prob": 0.012220842763781548
        },
        {
            "id": 22,
            "seek": 5636,
            "start": 56.36,
            "end": 60.16,
            "text": " So they're not as honest as they ideally should be.",
            "tokens": [
                50363,
                1406,
                484,
                821,
                407,
                355,
                5508,
                355,
                484,
                30274,
                815,
                307,
                13,
                50553
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 23,
            "seek": 5636,
            "start": 60.16,
            "end": 62.12,
            "text": " And it's very subjective and biased, too,",
            "tokens": [
                50553,
                843,
                340,
                338,
                845,
                19088,
                290,
                21925,
                11,
                1165,
                11,
                50651
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 24,
            "seek": 5636,
            "start": 62.12,
            "end": 67.44,
            "text": " because what an ideal presentation should look like for them",
            "tokens": [
                50651,
                780,
                644,
                281,
                7306,
                10470,
                815,
                804,
                588,
                329,
                606,
                50917
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 25,
            "seek": 5636,
            "start": 67.44,
            "end": 70.76,
            "text": " could be very different for different people",
            "tokens": [
                50917,
                714,
                307,
                845,
                1180,
                329,
                1180,
                661,
                51083
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 26,
            "seek": 5636,
            "start": 70.76,
            "end": 73.92,
            "text": " and what it ideally should be.",
            "tokens": [
                51083,
                290,
                644,
                340,
                30274,
                815,
                307,
                13,
                51241
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 27,
            "seek": 5636,
            "start": 73.92,
            "end": 75.72,
            "text": " So those are the barriers.",
            "tokens": [
                51241,
                1406,
                883,
                389,
                262,
                14725,
                13,
                51331
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 28,
            "seek": 5636,
            "start": 75.72,
            "end": 78.08,
            "text": " And also, people are extremely, like,",
            "tokens": [
                51331,
                843,
                635,
                11,
                661,
                389,
                4457,
                11,
                588,
                11,
                51449
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 29,
            "seek": 5636,
            "start": 78.08,
            "end": 80.72,
            "text": " they're not aware of how they're speaking in a presentation",
            "tokens": [
                51449,
                484,
                821,
                407,
                3910,
                286,
                703,
                484,
                821,
                5486,
                287,
                257,
                10470,
                51581
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 30,
            "seek": 5636,
            "start": 80.72,
            "end": 83.36,
            "text": " because there's a lot to think about while presenting.",
            "tokens": [
                51581,
                780,
                612,
                338,
                257,
                1256,
                284,
                892,
                546,
                981,
                17728,
                13,
                51713
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 31,
            "seek": 5636,
            "start": 83.36,
            "end": 85.0,
            "text": " Like when you're speaking, you're actually",
            "tokens": [
                51713,
                4525,
                618,
                345,
                821,
                5486,
                11,
                345,
                821,
                1682,
                51795
            ],
            "temperature": 0.0,
            "avg_logprob": -0.19656736954398776,
            "compression_ratio": 1.8641975308641976,
            "no_speech_prob": 0.011853528209030628
        },
        {
            "id": 32,
            "seek": 8500,
            "start": 85.0,
            "end": 86.88,
            "text": " focused on thinking about what you're going to say",
            "tokens": [
                50363,
                5670,
                319,
                3612,
                546,
                644,
                345,
                821,
                1016,
                284,
                910,
                50457
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 33,
            "seek": 8500,
            "start": 86.88,
            "end": 88.2,
            "text": " and trying to make sense.",
            "tokens": [
                50457,
                290,
                2111,
                284,
                787,
                2565,
                13,
                50523
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 34,
            "seek": 8500,
            "start": 88.2,
            "end": 90.6,
            "text": " Like, you need to make the content.",
            "tokens": [
                50523,
                4525,
                11,
                345,
                761,
                284,
                787,
                262,
                2695,
                13,
                50643
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 35,
            "seek": 8500,
            "start": 90.6,
            "end": 95.2,
            "text": " The flow needs to be such that the content comes across",
            "tokens": [
                50643,
                383,
                5202,
                2476,
                284,
                307,
                884,
                326,
                262,
                2695,
                2058,
                1973,
                50873
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 36,
            "seek": 8500,
            "start": 95.2,
            "end": 97.76,
            "text": " to the audience in a way that it makes sense to them.",
            "tokens": [
                50873,
                284,
                262,
                5386,
                287,
                257,
                835,
                326,
                340,
                1838,
                2565,
                284,
                606,
                13,
                51001
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 37,
            "seek": 8500,
            "start": 97.76,
            "end": 99.76,
            "text": " So you don't have enough bandwidth left",
            "tokens": [
                51001,
                1406,
                345,
                836,
                470,
                423,
                1576,
                19484,
                1364,
                51101
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 38,
            "seek": 8500,
            "start": 99.76,
            "end": 102.32,
            "text": " to actually focus on your speaking habits,",
            "tokens": [
                51101,
                284,
                1682,
                2962,
                319,
                534,
                5486,
                13870,
                11,
                51229
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 39,
            "seek": 8500,
            "start": 102.32,
            "end": 103.52,
            "text": " whether you're pacing it properly,",
            "tokens": [
                51229,
                1771,
                345,
                821,
                37572,
                340,
                6105,
                11,
                51289
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 40,
            "seek": 8500,
            "start": 103.52,
            "end": 105.28,
            "text": " whether you're using too many fillers,",
            "tokens": [
                51289,
                1771,
                345,
                821,
                1262,
                1165,
                867,
                6070,
                364,
                11,
                51377
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 41,
            "seek": 8500,
            "start": 105.28,
            "end": 107.32,
            "text": " or whether you're speaking clearly.",
            "tokens": [
                51377,
                393,
                1771,
                345,
                821,
                5486,
                4084,
                13,
                51479
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 42,
            "seek": 8500,
            "start": 107.32,
            "end": 109.28,
            "text": " So there's not enough bandwidth to that.",
            "tokens": [
                51479,
                1406,
                612,
                338,
                407,
                1576,
                19484,
                284,
                326,
                13,
                51577
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 43,
            "seek": 8500,
            "start": 109.28,
            "end": 110.64,
            "text": " And then again, the human feedback bit,",
            "tokens": [
                51577,
                843,
                788,
                757,
                11,
                262,
                1692,
                7538,
                1643,
                11,
                51645
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 44,
            "seek": 8500,
            "start": 110.64,
            "end": 114.8,
            "text": " which is very subjective, generic, and heavily sugar-coated.",
            "tokens": [
                51645,
                543,
                318,
                845,
                19088,
                11,
                14276,
                11,
                290,
                7272,
                7543,
                12,
                1073,
                515,
                13,
                51853
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16974159189172694,
            "compression_ratio": 1.8084415584415585,
            "no_speech_prob": 0.05194132775068283
        },
        {
            "id": 45,
            "seek": 11480,
            "start": 114.8,
            "end": 115.64,
            "text": " So that's the problem.",
            "tokens": [
                50363,
                1406,
                326,
                338,
                262,
                1917,
                13,
                50405
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 46,
            "seek": 11480,
            "start": 115.64,
            "end": 117.36,
            "text": " And the solution is verbal vector.",
            "tokens": [
                50405,
                843,
                262,
                4610,
                318,
                17755,
                15879,
                13,
                50491
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 47,
            "seek": 11480,
            "start": 117.36,
            "end": 120.32,
            "text": " Again, I'll explain the vector a bit later in the name.",
            "tokens": [
                50491,
                6521,
                11,
                314,
                1183,
                4727,
                262,
                15879,
                257,
                1643,
                1568,
                287,
                262,
                1438,
                13,
                50639
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 48,
            "seek": 11480,
            "start": 120.32,
            "end": 121.88,
            "text": " It doesn't really make sense right now,",
            "tokens": [
                50639,
                632,
                1595,
                470,
                1107,
                787,
                2565,
                826,
                783,
                11,
                50717
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 49,
            "seek": 11480,
            "start": 121.88,
            "end": 125.72,
            "text": " but then it will make sense soon.",
            "tokens": [
                50717,
                475,
                788,
                340,
                481,
                787,
                2565,
                2582,
                13,
                50909
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 50,
            "seek": 11480,
            "start": 125.72,
            "end": 127.8,
            "text": " So the concept is a web application for now,",
            "tokens": [
                50909,
                1406,
                262,
                3721,
                318,
                257,
                3992,
                3586,
                329,
                783,
                11,
                51013
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 51,
            "seek": 11480,
            "start": 127.8,
            "end": 130.92,
            "text": " as you saw in the demo.",
            "tokens": [
                51013,
                355,
                345,
                2497,
                287,
                262,
                13605,
                13,
                51169
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 52,
            "seek": 11480,
            "start": 130.92,
            "end": 134.0,
            "text": " It'll analyze audio recordings to provide comprehensive",
            "tokens": [
                51169,
                632,
                1183,
                16602,
                6597,
                18813,
                284,
                2148,
                9815,
                51323
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 53,
            "seek": 11480,
            "start": 134.0,
            "end": 136.4,
            "text": " communication feedback, which you will see soon,",
            "tokens": [
                51323,
                6946,
                7538,
                11,
                543,
                345,
                481,
                766,
                2582,
                11,
                51443
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 54,
            "seek": 11480,
            "start": 136.4,
            "end": 138.88,
            "text": " based on whenever I stop the recording.",
            "tokens": [
                51443,
                1912,
                319,
                8797,
                314,
                2245,
                262,
                8296,
                13,
                51567
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 55,
            "seek": 11480,
            "start": 138.88,
            "end": 143.04,
            "text": " And once the LLM is done processing all of the inputs.",
            "tokens": [
                51567,
                843,
                1752,
                262,
                27140,
                44,
                318,
                1760,
                7587,
                477,
                286,
                262,
                17311,
                13,
                51775
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15352675585242792,
            "compression_ratio": 1.6642335766423357,
            "no_speech_prob": 0.0042295739986002445
        },
        {
            "id": 56,
            "seek": 14304,
            "start": 143.04,
            "end": 145.51999999999998,
            "text": " And the core pipeline, it looks like this.",
            "tokens": [
                50363,
                843,
                262,
                4755,
                11523,
                11,
                340,
                3073,
                588,
                428,
                13,
                50487
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 57,
            "seek": 14304,
            "start": 145.51999999999998,
            "end": 148.44,
            "text": " The input is either you speak to it,",
            "tokens": [
                50487,
                383,
                5128,
                318,
                2035,
                345,
                2740,
                284,
                340,
                11,
                50633
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 58,
            "seek": 14304,
            "start": 148.44,
            "end": 152.04,
            "text": " you record something live, or you upload an audio clip.",
            "tokens": [
                50633,
                345,
                1700,
                1223,
                2107,
                11,
                393,
                345,
                9516,
                281,
                6597,
                10651,
                13,
                50813
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 59,
            "seek": 14304,
            "start": 152.04,
            "end": 155.64,
            "text": " And once you do that, the pipeline gets triggered.",
            "tokens": [
                50813,
                843,
                1752,
                345,
                466,
                326,
                11,
                262,
                11523,
                3011,
                13973,
                13,
                50993
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 60,
            "seek": 14304,
            "start": 155.64,
            "end": 159.0,
            "text": " First, the speech to text bit, which is done using whisper,",
            "tokens": [
                50993,
                3274,
                11,
                262,
                4046,
                284,
                2420,
                1643,
                11,
                543,
                318,
                1760,
                1262,
                31992,
                11,
                51161
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 61,
            "seek": 14304,
            "start": 159.0,
            "end": 160.07999999999998,
            "text": " that gets triggered.",
            "tokens": [
                51161,
                326,
                3011,
                13973,
                13,
                51215
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 62,
            "seek": 14304,
            "start": 160.07999999999998,
            "end": 162.72,
            "text": " And you get a transcription out of it.",
            "tokens": [
                51215,
                843,
                345,
                651,
                257,
                26955,
                503,
                286,
                340,
                13,
                51347
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 63,
            "seek": 14304,
            "start": 162.72,
            "end": 164.88,
            "text": " So your audio is converted to text,",
            "tokens": [
                51347,
                1406,
                534,
                6597,
                318,
                11513,
                284,
                2420,
                11,
                51455
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 64,
            "seek": 14304,
            "start": 164.88,
            "end": 167.04,
            "text": " and you also get a transcript from it.",
            "tokens": [
                51455,
                290,
                345,
                635,
                651,
                257,
                14687,
                422,
                340,
                13,
                51563
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 65,
            "seek": 14304,
            "start": 167.04,
            "end": 170.51999999999998,
            "text": " Once that is done, we move to the feature extraction part,",
            "tokens": [
                51563,
                4874,
                326,
                318,
                1760,
                11,
                356,
                1445,
                284,
                262,
                3895,
                22236,
                636,
                11,
                51737
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1294584195475933,
            "compression_ratio": 1.7670682730923695,
            "no_speech_prob": 0.0025738885160535574
        },
        {
            "id": 66,
            "seek": 17052,
            "start": 170.52,
            "end": 173.72,
            "text": " which calculates quantitative metrics from the audio.",
            "tokens": [
                50363,
                543,
                43707,
                26610,
                20731,
                422,
                262,
                6597,
                13,
                50523
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 67,
            "seek": 17052,
            "start": 173.72,
            "end": 176.0,
            "text": " So we use a library called librosa for that,",
            "tokens": [
                50523,
                1406,
                356,
                779,
                257,
                5888,
                1444,
                9195,
                4951,
                64,
                329,
                326,
                11,
                50637
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 68,
            "seek": 17052,
            "start": 176.0,
            "end": 178.68,
            "text": " which is able to calculate these metrics,",
            "tokens": [
                50637,
                543,
                318,
                1498,
                284,
                15284,
                777,
                20731,
                11,
                50771
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 69,
            "seek": 17052,
            "start": 178.68,
            "end": 183.12,
            "text": " such as base, pauses, pitch, and volume variation.",
            "tokens": [
                50771,
                884,
                355,
                2779,
                11,
                37622,
                11,
                7078,
                11,
                290,
                6115,
                12291,
                13,
                50993
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 70,
            "seek": 17052,
            "start": 183.12,
            "end": 186.4,
            "text": " And then also certain text metrics, such as fill-o-words,",
            "tokens": [
                50993,
                843,
                788,
                635,
                1728,
                2420,
                20731,
                11,
                884,
                355,
                6070,
                12,
                78,
                12,
                10879,
                11,
                51157
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 71,
            "seek": 17052,
            "start": 186.4,
            "end": 188.84,
            "text": " how many fill-o-words we use, what were they,",
            "tokens": [
                51157,
                703,
                867,
                6070,
                12,
                78,
                12,
                10879,
                356,
                779,
                11,
                644,
                547,
                484,
                11,
                51279
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 72,
            "seek": 17052,
            "start": 188.84,
            "end": 191.24,
            "text": " sentence length, and unique words.",
            "tokens": [
                51279,
                6827,
                4129,
                11,
                290,
                3748,
                2456,
                13,
                51399
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 73,
            "seek": 17052,
            "start": 191.24,
            "end": 195.52,
            "text": " And then scores will be derived from the LLM analysis.",
            "tokens": [
                51399,
                843,
                788,
                8198,
                481,
                307,
                10944,
                422,
                262,
                27140,
                44,
                3781,
                13,
                51613
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 74,
            "seek": 17052,
            "start": 195.52,
            "end": 197.36,
            "text": " This is done once I have the transcript,",
            "tokens": [
                51613,
                770,
                318,
                1760,
                1752,
                314,
                423,
                262,
                14687,
                11,
                51705
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2340846428504357,
            "compression_ratio": 1.697211155378486,
            "no_speech_prob": 0.06350164115428925
        },
        {
            "id": 75,
            "seek": 19736,
            "start": 197.36,
            "end": 200.32000000000002,
            "text": " and the feature is JSON file.",
            "tokens": [
                50363,
                290,
                262,
                3895,
                318,
                19449,
                2393,
                13,
                50511
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 76,
            "seek": 19736,
            "start": 200.32000000000002,
            "end": 203.60000000000002,
            "text": " I'll combine these two features, the text and the audio features,",
            "tokens": [
                50511,
                314,
                1183,
                12082,
                777,
                734,
                3033,
                11,
                262,
                2420,
                290,
                262,
                6597,
                3033,
                11,
                50675
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 77,
            "seek": 19736,
            "start": 203.60000000000002,
            "end": 205.32000000000002,
            "text": " and make a JSON out of it.",
            "tokens": [
                50675,
                290,
                787,
                257,
                19449,
                503,
                286,
                340,
                13,
                50761
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 78,
            "seek": 19736,
            "start": 205.32000000000002,
            "end": 210.44000000000003,
            "text": " These two files will act as context with the LLM",
            "tokens": [
                50761,
                2312,
                734,
                3696,
                481,
                719,
                355,
                4732,
                351,
                262,
                27140,
                44,
                51017
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 79,
            "seek": 19736,
            "start": 210.44000000000003,
            "end": 212.8,
            "text": " with a very well-crafted problem for the LLM,",
            "tokens": [
                51017,
                351,
                257,
                845,
                880,
                12,
                39160,
                1917,
                329,
                262,
                27140,
                44,
                11,
                51135
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 80,
            "seek": 19736,
            "start": 212.8,
            "end": 216.08,
            "text": " which is, again, a lower fine-tuned llama",
            "tokens": [
                51135,
                543,
                318,
                11,
                757,
                11,
                257,
                2793,
                3734,
                12,
                28286,
                276,
                32660,
                1689,
                51299
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 81,
            "seek": 19736,
            "start": 216.08,
            "end": 220.0,
            "text": " 3 with 8 billion parameters.",
            "tokens": [
                51299,
                513,
                351,
                807,
                2997,
                10007,
                13,
                51495
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 82,
            "seek": 19736,
            "start": 220.0,
            "end": 223.52,
            "text": " And then once the LLM gets all of this as input as context,",
            "tokens": [
                51495,
                843,
                788,
                1752,
                262,
                27140,
                44,
                3011,
                477,
                286,
                428,
                355,
                5128,
                355,
                4732,
                11,
                51671
            ],
            "temperature": 0.0,
            "avg_logprob": -0.210145326761099,
            "compression_ratio": 1.6036866359447004,
            "no_speech_prob": 0.040414683520793915
        },
        {
            "id": 83,
            "seek": 22352,
            "start": 223.52,
            "end": 229.36,
            "text": " it will output the feedback in the structured way.",
            "tokens": [
                50363,
                340,
                481,
                5072,
                262,
                7538,
                287,
                262,
                20793,
                835,
                13,
                50655
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 84,
            "seek": 22352,
            "start": 229.36,
            "end": 231.56,
            "text": " And this is where the vector name comes from.",
            "tokens": [
                50655,
                843,
                428,
                318,
                810,
                262,
                15879,
                1438,
                2058,
                422,
                13,
                50765
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 85,
            "seek": 22352,
            "start": 231.56,
            "end": 233.88,
            "text": " Vector storage, I still haven't implemented this",
            "tokens": [
                50765,
                20650,
                6143,
                11,
                314,
                991,
                4398,
                470,
                9177,
                428,
                50881
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 86,
            "seek": 22352,
            "start": 233.88,
            "end": 236.92000000000002,
            "text": " in the front end, but then the back end is ready for this.",
            "tokens": [
                50881,
                287,
                262,
                2166,
                886,
                11,
                475,
                788,
                262,
                736,
                886,
                318,
                3492,
                329,
                428,
                13,
                51033
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 87,
            "seek": 22352,
            "start": 236.92000000000002,
            "end": 241.36,
            "text": " I will implement it soon, maybe after the presentation.",
            "tokens": [
                51033,
                314,
                481,
                3494,
                340,
                2582,
                11,
                3863,
                706,
                262,
                10470,
                13,
                51255
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 88,
            "seek": 22352,
            "start": 241.36,
            "end": 244.20000000000002,
            "text": " Didn't have enough time to do that.",
            "tokens": [
                51255,
                31279,
                470,
                423,
                1576,
                640,
                284,
                466,
                326,
                13,
                51397
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 89,
            "seek": 22352,
            "start": 244.20000000000002,
            "end": 247.24,
            "text": " So once the transcript is generated by Whisper,",
            "tokens": [
                51397,
                1406,
                1752,
                262,
                14687,
                318,
                7560,
                416,
                28424,
                525,
                11,
                51549
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 90,
            "seek": 22352,
            "start": 247.24,
            "end": 250.56,
            "text": " the speech-to-text model, the transcript",
            "tokens": [
                51549,
                262,
                4046,
                12,
                1462,
                12,
                5239,
                2746,
                11,
                262,
                14687,
                51715
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 91,
            "seek": 22352,
            "start": 250.56,
            "end": 252.8,
            "text": " is broken down into multiple chunks,",
            "tokens": [
                51715,
                318,
                5445,
                866,
                656,
                3294,
                22716,
                11,
                51827
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17856386545542124,
            "compression_ratio": 1.6356589147286822,
            "no_speech_prob": 0.03663506358861923
        },
        {
            "id": 92,
            "seek": 25280,
            "start": 252.8,
            "end": 255.48000000000002,
            "text": " and then it's stored in the vector database",
            "tokens": [
                50363,
                290,
                788,
                340,
                338,
                8574,
                287,
                262,
                15879,
                6831,
                50497
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 93,
            "seek": 25280,
            "start": 255.48000000000002,
            "end": 257.72,
            "text": " in its equivalent vector embedding.",
            "tokens": [
                50497,
                287,
                663,
                7548,
                15879,
                11525,
                12083,
                13,
                50609
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 94,
            "seek": 25280,
            "start": 257.72,
            "end": 259.96000000000004,
            "text": " And then the ideal use case for this",
            "tokens": [
                50609,
                843,
                788,
                262,
                7306,
                779,
                1339,
                329,
                428,
                50721
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 95,
            "seek": 25280,
            "start": 259.96000000000004,
            "end": 262.72,
            "text": " is once you're done with the presentation, once it's gone,",
            "tokens": [
                50721,
                318,
                1752,
                345,
                821,
                1760,
                351,
                262,
                10470,
                11,
                1752,
                340,
                338,
                3750,
                11,
                50859
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 96,
            "seek": 25280,
            "start": 262.72,
            "end": 264.76,
            "text": " there's no way to retrieve whatever is set,",
            "tokens": [
                50859,
                612,
                338,
                645,
                835,
                284,
                19818,
                4232,
                318,
                900,
                11,
                50961
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 97,
            "seek": 25280,
            "start": 264.76,
            "end": 266.44,
            "text": " or whatever knowledge was delivered.",
            "tokens": [
                50961,
                393,
                4232,
                3725,
                373,
                6793,
                13,
                51045
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 98,
            "seek": 25280,
            "start": 266.44,
            "end": 268.04,
            "text": " So once you have a transcript for that,",
            "tokens": [
                51045,
                1406,
                1752,
                345,
                423,
                257,
                14687,
                329,
                326,
                11,
                51125
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 99,
            "seek": 25280,
            "start": 268.04,
            "end": 270.12,
            "text": " you can actually query it, which makes a lot of sense.",
            "tokens": [
                51125,
                345,
                460,
                1682,
                12405,
                340,
                11,
                543,
                1838,
                257,
                1256,
                286,
                2565,
                13,
                51229
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 100,
            "seek": 25280,
            "start": 270.12,
            "end": 272.12,
            "text": " It's basically like a note-taker.",
            "tokens": [
                51229,
                632,
                338,
                6209,
                588,
                257,
                3465,
                12,
                30157,
                13,
                51329
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 101,
            "seek": 25280,
            "start": 272.12,
            "end": 274.68,
            "text": " Once you're in class, if you can record it,",
            "tokens": [
                51329,
                4874,
                345,
                821,
                287,
                1398,
                11,
                611,
                345,
                460,
                1700,
                340,
                11,
                51457
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 102,
            "seek": 25280,
            "start": 274.68,
            "end": 279.2,
            "text": " and then query it later, you have all the notes there.",
            "tokens": [
                51457,
                290,
                788,
                12405,
                340,
                1568,
                11,
                345,
                423,
                477,
                262,
                4710,
                612,
                13,
                51683
            ],
            "temperature": 0.0,
            "avg_logprob": -0.14919394877419542,
            "compression_ratio": 1.76,
            "no_speech_prob": 0.002007522154599428
        },
        {
            "id": 103,
            "seek": 27920,
            "start": 279.2,
            "end": 281.88,
            "text": " I haven't implemented that yet in the front end, though.",
            "tokens": [
                50363,
                314,
                4398,
                470,
                9177,
                326,
                1865,
                287,
                262,
                2166,
                886,
                11,
                996,
                13,
                50497
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3914307706496295,
            "compression_ratio": 1.1734693877551021,
            "no_speech_prob": 0.04645742103457451
        },
        {
            "id": 104,
            "seek": 27920,
            "start": 283.92,
            "end": 285.96,
            "text": " I think I should stop the recording now.",
            "tokens": [
                50599,
                314,
                892,
                314,
                815,
                2245,
                262,
                8296,
                783,
                13,
                50701
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3914307706496295,
            "compression_ratio": 1.1734693877551021,
            "no_speech_prob": 0.04645742103457451
        },
        {
            "id": 105,
            "seek": 27920,
            "start": 285.96,
            "end": 286.8,
            "text": " So that it has...",
            "tokens": [
                50701,
                1406,
                326,
                340,
                468,
                986,
                50743
            ],
            "temperature": 0.0,
            "avg_logprob": -0.3914307706496295,
            "compression_ratio": 1.1734693877551021,
            "no_speech_prob": 0.04645742103457451
        }
    ],
    "language": "en"
}